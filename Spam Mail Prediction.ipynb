{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c6ae39-438c-4066-ac8c-81cbfcf6b3d6",
   "metadata": {},
   "source": [
    "# Spam Mail Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db250c39-0771-4d3c-80d0-d222284f5f9d",
   "metadata": {},
   "source": [
    "**WORKFLOW:**\r\n",
    "\r\n",
    "1. **Data Collection**: First, we gather the email data, which includes both spam and ham emails. This data will be used to train our machine learning model.\r\n",
    "\r\n",
    "2. **Data Preprocessing**: Next, we preprocess the data by converting the text and paragraph data into meaningful numerical representations.\r\n",
    "\r\n",
    "3. **Data Splitting and Model Training**: After preprocessing, we split the dataset into training and testing data. The training data is used to train our machine learning model, while the test data is used to evaluate it. We will use a logistic regression model, as it is well-suited for binary classification problems, where there are two classes to classify—in this case, spam and ham emails.\r\n",
    "\r\n",
    "4. **Model Prediction**: Once the model is trained, it can predict whether a new email is spam or ham based on the trained logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a321c2-17e5-4214-b8c1-37ab7981ddbb",
   "metadata": {},
   "source": [
    "## Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c33e4e-bbac-4d1a-b28c-46f4e921bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a88cd5-1f49-4c6e-b9b4-bf061fd1fcc9",
   "metadata": {},
   "source": [
    "## Data Collection & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57aa05a4-f69b-44ce-84ea-eafe46620186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data from csv file to a pandas dataframe\n",
    "raw_mail_data = pd.read_csv('mail_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3889126a-2c3d-4c7b-a11d-06ffa6c40e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...       ...                                                ...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568      ham               Will ü b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(raw_mail_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12423d99-3e71-437f-9c3c-00adbe14de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the null values with a null string\n",
    "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a7838b2-31ad-498b-a800-152555f3c323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the first 5 rows of the dataframe\n",
    "mail_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d023c5f-24ee-4eb3-8dd8-863a6d02ab29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows and columns in the dataframe\n",
    "mail_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba973c-ed7f-4e4c-91bb-747d0e045203",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60db2b7c-9b5c-4021-9496-135aed4cbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label spam mail as 0; ham mail as 1;\n",
    "\n",
    "# Label all instances where the 'Category' column has 'spam' as 0\n",
    "mail_data.loc[mail_data['Category'] == 'spam', 'Category',] = 0\n",
    "\n",
    "# Label all instances where the 'Category' column has 'ham' as 1\n",
    "mail_data.loc[mail_data['Category'] == 'ham', 'Category',] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ddafc-7b8e-4eab-beec-10656fa59102",
   "metadata": {},
   "source": [
    "spam - 0 \\\n",
    "ham - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6bbfcf8-a313-4314-9aea-efdc041eaa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the data as texts and label\n",
    "\n",
    "X = mail_data['Message']\n",
    "\n",
    "Y = mail_data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f896190e-f969-4228-9f6e-c7e516372300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Go until jurong point, crazy.. Available only ...\n",
      "1                           Ok lar... Joking wif u oni...\n",
      "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       U dun say so early hor... U c already then say...\n",
      "4       Nah I don't think he goes to usf, he lives aro...\n",
      "                              ...                        \n",
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5568                 Will ü b going to esplanade fr home?\n",
      "5569    Pity, * was in mood for that. So...any other s...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: Message, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a31b138-88a7-4816-b565-9d30c6ea0a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       0\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "5567    0\n",
      "5568    1\n",
      "5569    1\n",
      "5570    1\n",
      "5571    1\n",
      "Name: Category, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff17db21-aad3-4045-84ac-27684273d772",
   "metadata": {},
   "source": [
    "## Splitting the data into training data & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6cd12f3-3a18-4f5f-8f96-f74b2673e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0877c050-be59-4b9e-8735-96f324a4342f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,) (4457,) (1115,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa5be8-3e46-4300-b252-2329d5e75756",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "862bba72-7c1f-42cf-97b3-04ad67f56b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data to feature vectors that can be used as input to the Logistic Regression Model\n",
    "feature_extraction = TfidfVectorizer(min_df = 1, # Ignore words that appear less than once in the dataset\n",
    "                                     stop_words = 'english', # Remove common words (e.g., \"the\", \"and\") that don't add much value\n",
    "                                     lowercase = True) # Convert all text to lowercase for better processing\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data and transform it into feature vectors\n",
    "X_train_features = feature_extraction.fit_transform(X_train) \n",
    "X_test_features = feature_extraction.transform(X_test) # only transform because we don't want the model to see it.\n",
    "\n",
    "# Convert Y_train and Y_test to integer type as they are currently of object type\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd94269d-4283-4747-b590-0e047265ddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5413)\t0.6198254967574347\n",
      "  (0, 4456)\t0.4168658090846482\n",
      "  (0, 2224)\t0.413103377943378\n",
      "  (0, 3811)\t0.34780165336891333\n",
      "  (0, 2329)\t0.38783870336935383\n",
      "  (1, 4080)\t0.18880584110891163\n",
      "  (1, 3185)\t0.29694482957694585\n",
      "  (1, 3325)\t0.31610586766078863\n",
      "  (1, 2957)\t0.3398297002864083\n",
      "  (1, 2746)\t0.3398297002864083\n",
      "  (1, 918)\t0.22871581159877646\n",
      "  (1, 1839)\t0.2784903590561455\n",
      "  (1, 2758)\t0.3226407885943799\n",
      "  (1, 2956)\t0.33036995955537024\n",
      "  (1, 1991)\t0.33036995955537024\n",
      "  (1, 3046)\t0.2503712792613518\n",
      "  (1, 3811)\t0.17419952275504033\n",
      "  (2, 407)\t0.509272536051008\n",
      "  (2, 3156)\t0.4107239318312698\n",
      "  (2, 2404)\t0.45287711070606745\n",
      "  (2, 6601)\t0.6056811524587518\n",
      "  (3, 2870)\t0.5864269879324768\n",
      "  (3, 7414)\t0.8100020912469564\n",
      "  (4, 50)\t0.23633754072626942\n",
      "  (4, 5497)\t0.15743785051118356\n",
      "  :\t:\n",
      "  (4454, 4602)\t0.2669765732445391\n",
      "  (4454, 3142)\t0.32014451677763156\n",
      "  (4455, 2247)\t0.37052851863170466\n",
      "  (4455, 2469)\t0.35441545511837946\n",
      "  (4455, 5646)\t0.33545678464631296\n",
      "  (4455, 6810)\t0.29731757715898277\n",
      "  (4455, 6091)\t0.23103841516927642\n",
      "  (4455, 7113)\t0.30536590342067704\n",
      "  (4455, 3872)\t0.3108911491788658\n",
      "  (4455, 4715)\t0.30714144758811196\n",
      "  (4455, 6916)\t0.19636985317119715\n",
      "  (4455, 3922)\t0.31287563163368587\n",
      "  (4455, 4456)\t0.24920025316220423\n",
      "  (4456, 141)\t0.292943737785358\n",
      "  (4456, 647)\t0.30133182431707617\n",
      "  (4456, 6311)\t0.30133182431707617\n",
      "  (4456, 5569)\t0.4619395404299172\n",
      "  (4456, 6028)\t0.21034888000987115\n",
      "  (4456, 7154)\t0.24083218452280053\n",
      "  (4456, 7150)\t0.3677554681447669\n",
      "  (4456, 6249)\t0.17573831794959716\n",
      "  (4456, 6307)\t0.2752760476857975\n",
      "  (4456, 334)\t0.2220077711654938\n",
      "  (4456, 5778)\t0.16243064490100795\n",
      "  (4456, 2870)\t0.31523196273113385\n"
     ]
    }
   ],
   "source": [
    "# These are feature vectors where each sentence is assigned a score based on the vectorizer function\n",
    "# Displays a sparse matrix where each entry shows a word's TF-IDF score in a specific document\n",
    "# (document index, word index) -> TF-IDF score\n",
    "print(X_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d8291-b156-4edf-a99f-37b0fde525c2",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "998146de-f0ea-4af2-86d3-3a88957dc13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression() # Initialize the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff1b365b-c299-44b0-a540-3e9ffb7fa7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Logistic Regression model with the training data\n",
    "# This code trains the model by adjusting its parameters to learn the relationship between the feature vectors (X_train_features)\n",
    "# and the actual labels (Y_train). The model uses this training data to make predictions on new, unseen data.\n",
    "model.fit(X_train_features, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574663ec-ff7e-44a4-8b3f-7cd4613829d7",
   "metadata": {},
   "source": [
    "## Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "276bac16-69d9-44a1-8403-92add40eb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on training data\n",
    "\n",
    "# Predict labels for the training data using the trained model\n",
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "\n",
    "# Calculate the accuracy of the predictions compared to the true labels\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "422da6fb-5ac3-432f-804e-a6f41d1455f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data :  0.9670181736594121\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training data : ', accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ef546-23a8-425f-8a4a-d92607bd1691",
   "metadata": {},
   "source": [
    "**Observation:** We achieved an accuracy of over 96%. This means that if you use your model to predict 100 different emails, it will correctly classify 96 of them. Typically, an accuracy score above 75% indicates that the model is performing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0793e7d-cb09-44fc-bee2-7b693793a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test data\n",
    "\n",
    "# Predict labels for the test data using the trained model\n",
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "\n",
    "# Calculate the accuracy of the predictions compared to the true labels\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcd0d9eb-1c0a-4fb5-83de-f403c248477c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data :  0.9659192825112107\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test data : ', accuracy_on_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aceb7bf-1f6f-4054-9238-693056d3d427",
   "metadata": {},
   "source": [
    "**Question:** Why do we check the model's accuracy on training data using `Y_train` instead of using `Y_test`?\r\n",
    "\r\n",
    "**Answer:** Checking the model's accuracy on both the training data and the test data is important because it helps us identify if our model is overfitting. \r\n",
    "\r\n",
    "**Overfitting** occurs when a model performs very well on the training data but poorly on new, unseen data. Here's how it works:\r\n",
    "\r\n",
    "- **High Training Accuracy**: If the model has high accuracy on the training data (e.g., 96%), it means the model has learned the training data well.\r\n",
    "\r\n",
    "- **Low Test Accuracy**: If the model has low accuracy on the test data (e.g., 60%), it indicates that the model does not generalize well to new data.\r\n",
    "\r\n",
    "The large difference between training accuracy and test accuracy suggests overfitting, meaning the model is too closely tailored to the training data and is not performing well on new, unseen data. This usually happens when the model is too complex or has learned the noise in the training data rather than the underlying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3cd46f-f2c2-4c25-b462-181a1a588b3d",
   "metadata": {},
   "source": [
    "## Building a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef292704-e6c1-4910-b12c-b8a0cf2a7c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Ham mail\n"
     ]
    }
   ],
   "source": [
    "# This is the input data; it doesn't include the label, as the model will predict it.\n",
    "input_mail = [\"A gram usually runs like  &lt;#&gt; , a half eighth is smarter though and gets you almost a whole second gram for  &lt;#&gt;\"] \n",
    "\n",
    "# Convert text to feature vectors\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# Making Prediction\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "if prediction[0] == 1:\n",
    "    print(\"Ham mail\")\n",
    "else:\n",
    "    print(\"Spam mail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eceb6ac-dd82-49c6-8856-de9968aa52c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
